<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Visualizador de √Åudio de Frequ√™ncias</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            width: 100%;
            height: 100vh;
            background: #000;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            color: #fff;
        }

        .container {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 20px;
            z-index: 10;
        }

        h1 {
            font-size: 28px;
            margin-bottom: 10px;
            text-shadow: 0 0 10px rgba(255, 0, 200, 0.5);
        }

        .controls {
            display: flex;
            gap: 10px;
            align-items: center;
            flex-wrap: wrap;
            justify-content: center;
        }

        audio {
            width: 300px;
            max-width: 100%;
        }

        button {
            padding: 10px 20px;
            font-size: 16px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
        }

        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(102, 126, 234, 0.6);
        }

        button:active {
            transform: translateY(0);
        }

        button.active {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            box-shadow: 0 4px 15px rgba(245, 87, 108, 0.4);
        }

        canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            display: block;
        }

        .info {
            position: fixed;
            bottom: 20px;
            left: 20px;
            background: rgba(0, 0, 0, 0.9);
            padding: 15px;
            border-radius: 5px;
            font-size: 12px;
            max-width: 350px;
            border-left: 3px solid #667eea;
        }

        .status {
            margin-top: 10px;
            padding: 8px;
            background: rgba(102, 126, 234, 0.2);
            border-radius: 3px;
            font-size: 11px;
        }

        .status.error {
            background: rgba(245, 87, 108, 0.2);
            border-left: 2px solid #f5576c;
        }

        .status.success {
            background: rgba(76, 175, 80, 0.2);
            border-left: 2px solid #4caf50;
        }

        #fileInput {
            display: none;
        }
    </style>
</head>
<body>
    <canvas id="visualizer"></canvas>
    
    <div class="container">
        <h1>üéµ Visualizador de Frequ√™ncias</h1>
        <div class="controls">
            <audio id="audioPlayer" crossorigin="anonymous">
                Seu navegador n√£o suporta o elemento de √°udio.
            </audio>
            <button id="playBtn">‚ñ∂ Reproduzir</button>
            <button id="pauseBtn">‚è∏ Pausar</button>
        </div>
        <div class="controls">
            <button id="fileBtn">üìÅ Carregar Arquivo</button>
            <button id="micBtn">üé§ Usar Microfone</button>
        </div>
        <input type="file" id="fileInput" accept="audio/*">
    </div>

    <div class="info">
        <strong>‚ÑπÔ∏è Como usar:</strong><br>
        <strong>Op√ß√£o 1 (Recomendada):</strong> Clique em "üìÅ Carregar Arquivo" e selecione seu MP3 ou M4A<br><br>
        <strong>Op√ß√£o 2:</strong> Clique em "üé§ Usar Microfone" para visualizar √°udio do seu microfone<br><br>
        <div class="status" id="status"></div>
    </div>

    <script>
        const canvas = document.getElementById('visualizer');
        const ctx = canvas.getContext('2d');
        const audioPlayer = document.getElementById('audioPlayer');
        const playBtn = document.getElementById('playBtn');
        const pauseBtn = document.getElementById('pauseBtn');
        const fileBtn = document.getElementById('fileBtn');
        const micBtn = document.getElementById('micBtn');
        const fileInput = document.getElementById('fileInput');
        const status = document.getElementById('status');

        let audioContext;
        let analyser;
        let dataArray;
        let animationId;
        let isUsingMicrophone = false;

        function updateStatus(message, isError = false) {
            status.textContent = message;
            status.className = 'status ' + (isError ? 'error' : 'success');
        }

        function getAudioContext() {
            if (!audioContext) {
                const AudioCtx = window.AudioContext || window.webkitAudioContext;
                audioContext = new AudioCtx();
                console.log('‚úì AudioContext criado');
            }
            
            if (audioContext.state === 'suspended') {
                audioContext.resume();
                console.log('‚úì AudioContext resumed');
            }
            
            return audioContext;
        }

        function setupAnalyser() {
            const ctx = getAudioContext();
            
            if (!analyser) {
                analyser = ctx.createAnalyser();
                analyser.fftSize = 256;
                analyser.smoothingTimeConstant = 0.8;
                console.log('‚úì Analyser criado');
            }
            
            dataArray = new Uint8Array(analyser.frequencyBinCount);
            return analyser;
        }

        function startVisualization() {
            if (animationId) cancelAnimationFrame(animationId);
            resizeCanvas();
            draw();
        }

        function resizeCanvas() {
            canvas.width = window.innerWidth;
            canvas.height = window.innerHeight;
        }

        function draw() {
            animationId = requestAnimationFrame(draw);

            if (!analyser || !dataArray) return;

            analyser.getByteFrequencyData(dataArray);

            ctx.fillStyle = '#000';
            ctx.fillRect(0, 0, canvas.width, canvas.height);

            // Linha divis√≥ria no meio
            ctx.strokeStyle = 'rgba(100, 100, 100, 0.3)';
            ctx.lineWidth = 1;
            ctx.beginPath();
            ctx.moveTo(0, canvas.height / 2);
            ctx.lineTo(canvas.width, canvas.height / 2);
            ctx.stroke();

            const barWidth = (canvas.width / dataArray.length) * 2.5;
            const centerY = canvas.height / 2;
            let x = 0;

            for (let i = 0; i < dataArray.length; i++) {
                const barHeight = (dataArray[i] / 255) * (canvas.height / 2);
                const hue = (i / dataArray.length) * 60;

                ctx.fillStyle = `hsl(${hue}, 100%, 50%)`;

                const radius = barWidth / 2;
                const barX = x + barWidth / 2;

                // Barra para CIMA (da linha do meio para cima)
                const barYTop = centerY - barHeight;
                ctx.beginPath();
                ctx.moveTo(barX - barWidth / 2 + radius, barYTop);
                ctx.lineTo(barX + barWidth / 2 - radius, barYTop);
                ctx.quadraticCurveTo(barX + barWidth / 2, barYTop, barX + barWidth / 2, barYTop + radius);
                ctx.lineTo(barX + barWidth / 2, centerY);
                ctx.lineTo(barX - barWidth / 2, centerY);
                ctx.lineTo(barX - barWidth / 2, barYTop + radius);
                ctx.quadraticCurveTo(barX - barWidth / 2, barYTop, barX - barWidth / 2 + radius, barYTop);
                ctx.fill();

                // Barra para BAIXO (da linha do meio para baixo - espelho)
                const barYBottom = centerY + barHeight;
                ctx.beginPath();
                ctx.moveTo(barX - barWidth / 2 + radius, centerY);
                ctx.lineTo(barX + barWidth / 2 - radius, centerY);
                ctx.quadraticCurveTo(barX + barWidth / 2, centerY, barX + barWidth / 2, centerY + radius);
                ctx.lineTo(barX + barWidth / 2, barYBottom);
                ctx.lineTo(barX - barWidth / 2, barYBottom);
                ctx.lineTo(barX - barWidth / 2, centerY + radius);
                ctx.quadraticCurveTo(barX - barWidth / 2, centerY, barX - barWidth / 2 + radius, centerY);
                ctx.fill();

                ctx.shadowColor = `hsl(${hue}, 100%, 50%)`;
                ctx.shadowBlur = 10;

                x += barWidth + 1;
            }

            ctx.shadowBlur = 0;
        }

        // Carregar arquivo
        fileBtn.addEventListener('click', () => {
            fileInput.click();
        });

        fileInput.addEventListener('change', (e) => {
            const file = e.target.files[0];
            if (!file) return;

            try {
                const ctx = getAudioContext();
                setupAnalyser();

                const url = URL.createObjectURL(file);
                audioPlayer.src = url;
                
                // M√©todo alternativo: conectar diretamente ao analyser
                // usando um elemento de √°udio j√° conectado
                if (!audioPlayer.analyserConnected) {
                    const dest = ctx.destination;
                    
                    // Usar ScriptProcessorNode como ponte (deprecated mas funciona)
                    const processor = ctx.createScriptProcessor(4096, 1, 1);
                    processor.connect(dest);
                    
                    // Criar um analisador alternativo via elemento de √°udio
                    const dummy = ctx.createGain();
                    dummy.connect(analyser);
                    dummy.connect(processor);
                    
                    audioPlayer.analyserConnected = true;
                }

                // M√âTODO SIMPLES: usar a API de fetch para carregar o √°udio
                fetch(url)
                    .then(response => response.arrayBuffer())
                    .then(arrayBuffer => {
                        ctx.decodeAudioData(arrayBuffer, audioBuffer => {
                            const source = ctx.createBufferSource();
                            source.buffer = audioBuffer;
                            source.connect(analyser);
                            analyser.connect(ctx.destination);
                            source.start(0);
                            startVisualization();
                            updateStatus(`‚úÖ Tocando: ${file.name}`);
                        });
                    })
                    .catch(err => {
                        console.error('Erro ao carregar:', err);
                        updateStatus('‚ùå Erro: ' + err.message, true);
                    });

            } catch (err) {
                console.error('Erro:', err);
                updateStatus('‚ùå Erro: ' + err.message, true);
            }
        });

        // Usar microfone
        micBtn.addEventListener('click', async () => {
            try {
                micBtn.disabled = true;
                updateStatus('üîÑ Solicitando microfone...');

                const ctx = getAudioContext();
                setupAnalyser();

                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                const source = ctx.createMediaStreamAudioSource(stream);
                source.connect(analyser);
                analyser.connect(ctx.destination);

                isUsingMicrophone = true;
                fileBtn.classList.remove('active');
                micBtn.classList.add('active');

                startVisualization();
                updateStatus('‚úÖ Microfone ativado!');
                micBtn.disabled = false;

            } catch (err) {
                console.error('Erro microfone:', err);
                updateStatus('‚ùå Erro: ' + err.message, true);
                micBtn.disabled = false;
            }
        });

        playBtn.addEventListener('click', () => {
            if (audioPlayer.src) {
                audioPlayer.play();
                startVisualization();
            } else {
                updateStatus('‚ùå Carregue um arquivo', true);
            }
        });

        pauseBtn.addEventListener('click', () => {
            audioPlayer.pause();
        });

        window.addEventListener('resize', () => {
            if (canvas && animationId) resizeCanvas();
        });

        updateStatus('üëá Clique em "Carregar Arquivo" ou "Usar Microfone"');
    </script>
</body>
</html>